{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2fe729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e30487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDIT_UNION_ID</th>\n",
       "      <th>ACCOUNT_NUM</th>\n",
       "      <th>FLG_202201</th>\n",
       "      <th>FLG_202202</th>\n",
       "      <th>FLG_202203</th>\n",
       "      <th>FLG_202204</th>\n",
       "      <th>FLG_202205</th>\n",
       "      <th>FLG_202206</th>\n",
       "      <th>DEEP_CHANNELS_202201</th>\n",
       "      <th>DEEP_CHANNELS_202202</th>\n",
       "      <th>...</th>\n",
       "      <th>AMP_202203</th>\n",
       "      <th>AMP_202204</th>\n",
       "      <th>AMP_202205</th>\n",
       "      <th>AMP_202206</th>\n",
       "      <th>NUM_TRANSACTIONS_202201</th>\n",
       "      <th>NUM_TRANSACTIONS_202202</th>\n",
       "      <th>NUM_TRANSACTIONS_202203</th>\n",
       "      <th>NUM_TRANSACTIONS_202204</th>\n",
       "      <th>NUM_TRANSACTIONS_202205</th>\n",
       "      <th>NUM_TRANSACTIONS_202206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>ZWZZ!W</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>&amp;WXYY&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Y%@YZ&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>!W%&amp;#!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>%##AXY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREDIT_UNION_ID ACCOUNT_NUM  FLG_202201  FLG_202202  FLG_202203  FLG_202204  \\\n",
       "0               A      ZWZZ!W           1           1           1           1   \n",
       "1               A      &WXYY&           1           1           1           1   \n",
       "2               A      Y%@YZ&           1           1           1           1   \n",
       "3               A      !W%&#!           1           1           1           1   \n",
       "4               A      %##AXY           1           1           1           1   \n",
       "\n",
       "   FLG_202205  FLG_202206  DEEP_CHANNELS_202201  DEEP_CHANNELS_202202  ...  \\\n",
       "0           1           1                     0                     0  ...   \n",
       "1           1           1                     0                     0  ...   \n",
       "2           1           1                     0                     0  ...   \n",
       "3           1           1                     0                     0  ...   \n",
       "4           1           1                     0                     0  ...   \n",
       "\n",
       "   AMP_202203  AMP_202204  AMP_202205  AMP_202206  NUM_TRANSACTIONS_202201  \\\n",
       "0           3           3           2           4                       68   \n",
       "1           1           2           2           1                       14   \n",
       "2           2           2           1           2                       12   \n",
       "3           3           3           2           2                       38   \n",
       "4           3           2           3           2                       24   \n",
       "\n",
       "   NUM_TRANSACTIONS_202202  NUM_TRANSACTIONS_202203  NUM_TRANSACTIONS_202204  \\\n",
       "0                       86                      130                      100   \n",
       "1                        8                        4                       24   \n",
       "2                        6                       10                       12   \n",
       "3                       24                       36                       54   \n",
       "4                       12                       12                        8   \n",
       "\n",
       "   NUM_TRANSACTIONS_202205  NUM_TRANSACTIONS_202206  \n",
       "0                       68                      112  \n",
       "1                       12                       10  \n",
       "2                       12                       20  \n",
       "3                       72                       48  \n",
       "4                        6                       20  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Model Data Set (pseudo).csv',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d114e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91848, 68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3853474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make sure to create a copy of the data before we start altering it. Note that we don't change the original data we loaded.\n",
    "data = df.copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac166679",
   "metadata": {},
   "source": [
    "# Preparing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672f29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare independent variables (X) and dependent variable (y)\n",
    "\n",
    "# To avoid writing them out every time, we save the names of the estimators of our model in a list. \n",
    "independent_variables=[#PIX\n",
    "            'DEEP_PIX_202201',\n",
    "            'DEEP_PIX_202202',\n",
    "            'DEEP_PIX_202203',\n",
    "            'DEEP_PIX_202204',\n",
    "            'DEEP_PIX_202205',\n",
    "            #BILLS\n",
    "            'DEEP_BILLS_202201',\n",
    "            'DEEP_BILLS_202202',\n",
    "            'DEEP_BILLS_202203',\n",
    "            'DEEP_BILLS_202204',\n",
    "            'DEEP_BILLS_202205',\n",
    "            #CARDS\n",
    "            'DEEP_CARDS_202201',\n",
    "            'DEEP_CARDS_202202',\n",
    "            'DEEP_CARDS_202203',\n",
    "            'DEEP_CARDS_202204',\n",
    "            'DEEP_CARDS_202205',\n",
    "            #CHECKING\n",
    "            'DEEP_CHECKING_202201',\n",
    "            'DEEP_CHECKING_202202',\n",
    "            'DEEP_CHECKING_202203',\n",
    "            'DEEP_CHECKING_202204',\n",
    "            'DEEP_CHECKING_202205',\n",
    "            #CREDIT\n",
    "            'DEEP_CREDIT_202201',\n",
    "            'DEEP_CREDIT_202202',\n",
    "            'DEEP_CREDIT_202203',\n",
    "            'DEEP_CREDIT_202204',\n",
    "            'DEEP_CREDIT_202205',\n",
    "            #INVESTMENTS\n",
    "            'DEEP_INVESTMENTS_202201',\n",
    "            'DEEP_INVESTMENTS_202202',\n",
    "            'DEEP_INVESTMENTS_202203',\n",
    "            'DEEP_INVESTMENTS_202204',\n",
    "            'DEEP_INVESTMENTS_202205',\n",
    "            #PAYMENTS\n",
    "            'DEEP_PAYMENTS_202201',\n",
    "            'DEEP_PAYMENTS_202202',\n",
    "            'DEEP_PAYMENTS_202203',\n",
    "            'DEEP_PAYMENTS_202204',\n",
    "            'DEEP_PAYMENTS_202205',\n",
    "            #AMPLITUDE\n",
    "            'AMP_202201',\n",
    "            'AMP_202202',\n",
    "            'AMP_202203',\n",
    "            'AMP_202204',\n",
    "            'AMP_202205'\n",
    "           ]\n",
    "\n",
    "X = data[independent_variables]\n",
    "y = data['FLG_202206']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56850fdd",
   "metadata": {},
   "source": [
    "# Handling class imbalance\n",
    "\n",
    "We know from our exploratory analysis that this dataset will be havily imbalanced with churn on 6th month as the minority class (represented as inactivity on that month or FLG_202206 = 0).\n",
    "\n",
    "The problem with classifiers and class inbalance is that the classifier will more easily classify the majority class, simply because most cases are of that class. For that reason model performance metrics have to be carefully selected. Precision, recall and F1 will be used as the main metrics for evaluating performance. In our specfic case we our most interested in those metrics regarding the prediction of the minority class (0 in our case).\n",
    "\n",
    "So in this study we will contrast the use of two wildly used classification models: Logistic Regression and RandomTreeClassifier, both with SciKit Learn implementations. Tree Ensembles our suposabily better at handling inbalance. And a common technique for getting better results is using resampling techniques. For that we will contrast model metrics on baseline models with resampled models (RandomOverSampling, SMOTE and NearMisses)\n",
    "\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://medium.com/grabngoinfo/four-oversampling-and-under-sampling-methods-for-imbalanced-classification-using-python-7304aedf9037\n",
    "\n",
    "https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2de5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Primer on reading the Confusion Matrix\n",
    "# True Negative | False Positive\n",
    "# False Negative | True Positive\n",
    "\n",
    "# Precision \n",
    "# Measure of how many of the positive predictions made are correct (true positives).\n",
    "# Formula: TP/(TP+FP)\n",
    "\n",
    "# Recall \n",
    "# Measure of how many of the positive cases the classifier correctly predicted considering the over all positive cases in the data.\n",
    "# It is sometimes also referred to as Sensitivity\n",
    "# Formula: TP/(TP+FN)\n",
    "\n",
    "# Accuracy\n",
    "# Measure of the number of correct predictions over all predictions\n",
    "# Formula: (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfcc6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the modeling dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Model and performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve \n",
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter\n",
    "# Processing time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab435845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model_name,resampling_name,y_test,model_prediction,verbose):\n",
    "    \"\"\"\n",
    "    Prints the performance reports: Classification report and Confusion Matrix\n",
    "    \n",
    "    Inputs\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling method\n",
    "    y_test = Test vector\n",
    "    model_prediction = Prediction vector\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    Returns print with the reports\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    cr = classification_report(y_test, model_prediction)\n",
    "    cm = confusion_matrix(y_test, model_prediction)\n",
    "    print('\\n',model_name,'with',resampling_name,' Classification Report:')\n",
    "    print(cr)\n",
    "    print(cm)\n",
    "    \n",
    "    if verbose != 'off': print(\"\\nModel Performane processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    return cr,cm\n",
    "    \n",
    "    # #Precision-Recall Curve gives us the correct accuracy in this imbalanced dataset case. We can see that we have a very poor accuracy for the model.\n",
    "    # precision, recall, thresholds = precision_recall_curve(model_prediction, y_test)\n",
    "\n",
    "    # # create plot\n",
    "    # plt.plot(precision, recall, label='Precision-recall curve')\n",
    "    # plt.xlabel('Precision')\n",
    "    # plt.ylabel('Recall')\n",
    "    # plt.title('Precision-recall curve')\n",
    "    # plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7485c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(model_name,random_state,verbose):\n",
    "    \"\"\"\n",
    "    Instantiates and defines Classifier models.\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    Returns intantiated model according to users choice.\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    if verbose != 'off': print('\\nInstantiating',model_name,'model.')\n",
    "    rf = RandomForestClassifier(random_state = random_state)\n",
    "    lr =  LogisticRegression(random_state = random_state)\n",
    "    if model_name == 'Random Forest':\n",
    "        if verbose != 'off': print('\\nModel ready:',rf)\n",
    "        if verbose != 'off': print(\"Model Instatiating processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        return rf\n",
    "    elif model_name == 'Logistic Regression':\n",
    "        if verbose != 'off': print('\\nModel ready:',lr)\n",
    "        if verbose != 'off': print(\"Model Instatiating processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        return lr\n",
    "    else:\n",
    "        print('\\nNo compatible model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ae27bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_resample_sets(model_name,resampling_name,X,y,test_size,random_state,verbose):\n",
    "    \"\"\"\n",
    "    Splits and resamples X dataset and y vector.\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling method\n",
    "    X = DataFrame with independent variables\n",
    "    y = Vector with dependent (response) variable\n",
    "    test_size = Float (0 to 1) for test size porcentage of the train/test split\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    X_train = DataFrame with independent variables splitted for train set\n",
    "    X_test = DataFrame with independent variables splitted for test set\n",
    "    y_train = Vector with dependent variable splitted for train set\n",
    "    y_test = Vector with dependent variable splitted for test set\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    if verbose != 'off': print('\\nIniatialing split for train and test sets. \\nAnalyzing need for variable rescaling.')\n",
    "    if model_name == 'Logistic Regression':\n",
    "        if verbose != 'off': print('\\nLogistic Regression requies scaling. \\nVariable rescaling necessary.')\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_scaled\n",
    "\n",
    "        # Split into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,test_size = test_size, random_state = random_state)\n",
    "    elif model_name == 'Random Forest':\n",
    "        if verbose != 'off': print('\\nRandom Forest does not require rescalling.')\n",
    "        # Split into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    if verbose != 'off': print('\\nApplying resampling technique choosen.')\n",
    "    if resampling_name == 'Baseline':\n",
    "        if verbose != 'off': print(\"\\nBaseline doesn't require resampling.\")\n",
    "    elif resampling_name == 'Random Over Sampling':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = RandomOverSampler(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'SMOTE':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = SMOTE(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'NearMiss KNN':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = NearMiss(version=3,random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'Random Under Sampling':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = RandomUnderSampler(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    if verbose != 'off': print(\"\\nResampling processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c742e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model_name,resampling_name,X,y,random_state,test_size,verbose):\n",
    "    \"\"\"\n",
    "    Trains and Fits Models with different Resampling Techniques\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling technique name\n",
    "    X = DataFrame with independent variables\n",
    "    y = Vector with dependent (response) variable\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    model_prediction = Vector with chosen model with resampling predictions on the test set\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    print('\\n--------------------------------------------------------------------------------\\n--------------------------------------------------------------------------------')\n",
    "    if verbose != 'off': print('\\nStarting new sequence:',model_name,'with',resampling_name)\n",
    "    model_prediction = []\n",
    "    y_train_resampled = []  \n",
    " \n",
    "    \n",
    "    #Define model\n",
    "    model = define_model(model_name,random_state,verbose)\n",
    "    #Split train and test sets + Apply scaling when need + Apply resampling\n",
    "    X_train, X_test, y_train, y_test = split_resample_sets(model_name,resampling_name,X,y,test_size,random_state,verbose)\n",
    "    #Train model\n",
    "    if verbose != 'off': print('\\nFitting model.')\n",
    "    model = model.fit(X_train, y_train)\n",
    "    if verbose != 'off': print(\"\\nFitting model processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    #Predict on trained model\n",
    "    if verbose != 'off': print('\\nPredicting on model.')\n",
    "    model_prediction = model.predict(X_test) \n",
    "    if verbose != 'off': print(\"\\nModel prediction processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    #Evaluate model performance   \n",
    "    cr,cm = model_performance(model_name,resampling_name,y_test,model_prediction,verbose)\n",
    "    \n",
    "    print(\"\\nTotal processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return cr,cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bbdcf",
   "metadata": {},
   "source": [
    "## Processing and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e83623c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.00       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.52      0.50      0.49     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    1   422]\n",
      " [   14 13341]]\n",
      "\n",
      "Total processing time: --- 15.233237028121948 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.02      0.03       423\n",
      "           1       0.97      0.99      0.98     13355\n",
      "\n",
      "    accuracy                           0.96     13778\n",
      "   macro avg       0.53      0.51      0.51     13778\n",
      "weighted avg       0.94      0.96      0.95     13778\n",
      "\n",
      "[[    9   414]\n",
      " [   89 13266]]\n",
      "\n",
      "Total processing time: --- 24.936513423919678 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.14      0.14       423\n",
      "           1       0.97      0.97      0.97     13355\n",
      "\n",
      "    accuracy                           0.95     13778\n",
      "   macro avg       0.55      0.56      0.55     13778\n",
      "weighted avg       0.95      0.95      0.95     13778\n",
      "\n",
      "[[   60   363]\n",
      " [  391 12964]]\n",
      "\n",
      "Total processing time: --- 26.715983867645264 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.00       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.52      0.50      0.49     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    1   422]\n",
      " [   14 13341]]\n",
      "\n",
      "Total processing time: --- 10.896340131759644 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.77      0.16       423\n",
      "           1       0.99      0.75      0.85     13355\n",
      "\n",
      "    accuracy                           0.75     13778\n",
      "   macro avg       0.54      0.76      0.51     13778\n",
      "weighted avg       0.96      0.75      0.83     13778\n",
      "\n",
      "[[  327    96]\n",
      " [ 3337 10018]]\n",
      "\n",
      "Total processing time: --- 0.9614410400390625 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.48      0.50      0.49     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    0   423]\n",
      " [    6 13349]]\n",
      "\n",
      "Total processing time: --- 0.5146284103393555 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 358   65]\n",
      " [4032 9323]]\n",
      "\n",
      "Total processing time: --- 0.892829418182373 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.83      0.15       423\n",
      "           1       0.99      0.71      0.83     13355\n",
      "\n",
      "    accuracy                           0.71     13778\n",
      "   macro avg       0.54      0.77      0.49     13778\n",
      "weighted avg       0.96      0.71      0.81     13778\n",
      "\n",
      "[[ 353   70]\n",
      " [3864 9491]]\n",
      "\n",
      "Total processing time: --- 1.3115665912628174 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.48      0.50      0.49     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    0   423]\n",
      " [    6 13349]]\n",
      "\n",
      "Total processing time: --- 0.6053905487060547 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 359   64]\n",
      " [4062 9293]]\n",
      "\n",
      "Total processing time: --- 0.24335336685180664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#set shared variables\n",
    "random_state = 26\n",
    "test_size = 0.15\n",
    "#set model names\n",
    "model_name = ['Random Forest','Logistic Regression']\n",
    "#set resampling names\n",
    "resampling_name = ['Baseline','Random Over Sampling','SMOTE','Near Miss KNN','Random Under Sampling']\n",
    "\n",
    "model_prediction = []\n",
    "\n",
    "for model in model_name:\n",
    "    for resampling in resampling_name:\n",
    "        cr,cm = model_predict(model,resampling,X,y,random_state,test_size,'off')\n",
    "        model_prediction.append((model,resampling,cr,cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
