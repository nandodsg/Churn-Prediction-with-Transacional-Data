{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbb2247",
   "metadata": {},
   "source": [
    "# CRISP-DM Analysis for Business Problem: Innactivity prediction with transactional data\n",
    "\n",
    "This notebook is a companion to the Medium article (link bellow) the underlies the application with CRISP-DM methodology to understand, analyze and communicate a business problem through a proven and tested Data Science methodology.\n",
    "\n",
    "CRISP-DM comprises of 6 steps:\n",
    "\n",
    "Section 1: Business Understanding\n",
    "\n",
    "Section 2: Data Understanding\n",
    "\n",
    "Section 3: Data Preparation\n",
    "\n",
    "Section 4: Data Modeling\n",
    "\n",
    "Section 5: Evaluate the Results\n",
    "\n",
    "Section 6: Deployment\n",
    "\n",
    "Medium Article:\n",
    "https://medium.com/@fernandocarliniguimaraes/innactivity-prediction-using-machine-learning-on-transacional-data-642ef7c84674"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b6960",
   "metadata": {},
   "source": [
    "# Section 1: Business Understanding\n",
    "\n",
    "The broader business contextualization is laid in the companion Medium Article.\n",
    "A brief summary of the business undersating is laid out bellow:\n",
    "A Brazilian Credit Union wishes to preempively predict Mobile phone app innactivity in a six month window. \n",
    "\n",
    "The business value of such endeavor lies on: \n",
    "- (1) expanding use cases of a dataset (data enrichment may lead to revenue growth); \n",
    "- (2) deterring potential customer churn (avoid revenue lost);\n",
    "- (3) early detection of customer friction (garantee user satisfaction).\n",
    "\n",
    "The business questions that arise pertaing such objective are:\n",
    "\n",
    "### Question 1: What are aspects of a transactional dataset that can be used for understanding channel innactivity in a six month window?\n",
    "\n",
    "### Question 2: Are mono-product-family users more likely to have channel innactivity in a six month window?\n",
    "\n",
    "### Question 3: Can transactional data alone safely predict channel innactivity in a six month window?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e42988",
   "metadata": {},
   "source": [
    "# Section 2: Data Understanding\n",
    "\n",
    "### Credit Union's Transaction Dataset overview\n",
    "\n",
    "The Credit Union has several client channels. For this project we are looking at only of them: the mobile phone app. It has roughlly 4 million users, with an average of 40–45 Million transactions per month, about 40% of these are financial transacions (like paying a bill) and 60% non-financial (like looking up a bill receipt). Our main goal for the project is avoidind financial transaction innactivity, so we focused onlty on those.\n",
    "\n",
    "All of these transactions are stored in a main database that is daily ingested in AWS Data Lake. That was the interface I used to query the data and extract it for the project.\n",
    "\n",
    "The transacional database holds A LOT of information. But, for this project the most vital informations used were:\n",
    "\n",
    "- Time and date the transacion happend;\n",
    "- The transaction code;\n",
    "- The product family the transaction is part of (example: investment application and investment cashout are two different transactions of the same product family).¹\n",
    "- The Credit Union Member who solicited the transaction;\n",
    "- The Credit Union the Member is linked to;\n",
    "- The status of the transacion. Did it complete? Or was it canceled?\n",
    "- The channel through which the transaction was solicited;\n",
    "\n",
    "¹ There are 8 main product familys: Channels (managing your self service channel), Checking account (wire transfers), Payments (Government Tribute or company Slips), Bills (Water, Phone, etc), Credit (Loans), Cards (Credit and debit) and PIX(Brazil’s own instant payment financial product), Investments (Long Term Deposits, Market Shares);\n",
    "\n",
    "For this project I filtered the channel to be only the Mobile App. I also chose 5 medium sized Credit Unions from our system (we have over 140) so as to have a good amount of data, but not too much as to make the processing time too long. And also fixed a six month period to analyze data.\n",
    "\n",
    "### IMPORTANT OBSERVATION: \n",
    "This dataset is quite clean because it’s a high management information system. When we use the filters described above, like the channel filter and completed status filter, we flush out basically anything that could get in our way. The heavier data wrangling necessary is grouping the transaction codes into product families and that is still quite easy to accomplish.\n",
    "\n",
    "### Exploratory Analysis of the Transactional Database\n",
    "\n",
    "I have written a second article piece that show cases the method I used for both the exploratory analysis and also the model selection and development. Please check it out the article, specially the <b>Data understanding — What data do we have / need? Is it clean?</b> section for further insight.\n",
    "\n",
    "Link:\n",
    "https://medium.com/@fernandocarliniguimaraes/innactivity-prediction-using-machine-learning-on-transacional-data-642ef7c84674\n",
    "\n",
    "### Disclaimer about Compliance and Confidentiality\n",
    "\n",
    "Due to company compliance I had to do all of the data wrangling and manipulation on our AWS Data Lake server using Redash running a AWS Athena and AthenaSQL engine. Data was only available for extraction after anonymization. I've included in the repository a SQL file with a pseudo algorhitm that masks the sensible information (like dataset names and columns) and shows how data manipulation was done.\n",
    "\n",
    "GitHub Repo for this project: https://github.com/nandodsg/Innactivity-Prediction-with-Transactional-Data\n",
    "\n",
    "##### Queries using during exploratory analysis:\n",
    "1. pseudo query - exploratory analysis dataset (anonymous).sql :\n",
    "https://github.com/nandodsg/Innactivity-Prediction-with-Transactional-Data/blob/main/pseudo%20query%20-%20exploratory%20analysis%20dataset%20(anonymous).sql\n",
    "2. pseudo query - exporatory analysis - churn flags (anonymous).sql : \n",
    "https://github.com/nandodsg/Innactivity-Prediction-with-Transactional-Data/blob/main/pseudo%20query%20-%20exporatory%20analysis%20-%20churn%20flags%20(anonymous).sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54477166",
   "metadata": {},
   "source": [
    "# Section 3: Data Preparation\n",
    "\n",
    "There can be many approches when it comes to modelling this specific business problem. One way to look at is to think of this sixth month innactivity as a kind of “churn” that we would want to predict based on a series of features (predictors). On this approch we could elect a Classifier Model for the problem.\n",
    "\n",
    "On this solution framing we have to consider our dataset modeling base on individual and not on transactions (the would work for the Time Series model though).\n",
    "\n",
    "We need one individual per row, with all the features laid out on separate columns. Based on the exploratory analysis I want to construct my dataframe with the following blocks:\n",
    "\n",
    "- Account Number ID\n",
    "- Credit Union Number ID\n",
    "- Sixth Month Innactivity Flag (our future dependent variable)\n",
    "- A depth counter (number of transacionts) by month and by product family\n",
    "- An amplitude counter (number of diferente families used) by month\n",
    "- Total depth counter by month\n",
    "\n",
    "I extracted the data from the other 4 credit unions I had previously selected. This time bringing in every member who attendend one simple rule: they had to be active on the first by months of 2022. This extraction gave me a 91.848 long dataset, each row representing an unique individual.\n",
    "\n",
    "### Disclaimer about Compliance and Confidentiality\n",
    "\n",
    "Due to company compliance I had to do all of the data wrangling and manipulation on our AWS Data Lake server using Redash running a AWS Athena and AthenaSQL engine. Data was only available for extraction after anonymization. I've included in the repository a SQL file with a pseudo algorhitm that masks the sensible information (like dataset names and columns) and shows how data manipulation was done.\n",
    "\n",
    "GitHub Repo for this project: https://github.com/nandodsg/Innactivity-Prediction-with-Transactional-Data\n",
    "\n",
    "##### Query used to generate model dataset\n",
    "1. pseudo query - model dataset.SQL : \n",
    "https://github.com/nandodsg/Innactivity-Prediction-with-Transactional-Data/blob/main/pseudo%20query%20-%20model%20dataset.SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfb920",
   "metadata": {},
   "source": [
    "# Section 4: Data Modeling\n",
    "\n",
    "The following section details the development of 10 different Classifiers Models aimed at supporting the analyses of the three business questions.\n",
    "\n",
    "I have written a second article piece that show cases the method I used for both the exploratory analysis and also the model selection and development. Please check it out the article, specially the <b>Modeling — What modeling techniques should we apply?</b> and the <b>Evaluation — Which model best meets the business objectives?</b> sections for further insight.\n",
    "\n",
    "Link: https://medium.com/@fernandocarliniguimaraes/innactivity-prediction-using-machine-learning-on-transacional-data-642ef7c84674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2fe729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e30487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDIT_UNION_ID</th>\n",
       "      <th>ACCOUNT_NUM</th>\n",
       "      <th>FLG_202201</th>\n",
       "      <th>FLG_202202</th>\n",
       "      <th>FLG_202203</th>\n",
       "      <th>FLG_202204</th>\n",
       "      <th>FLG_202205</th>\n",
       "      <th>FLG_202206</th>\n",
       "      <th>DEEP_CHANNELS_202201</th>\n",
       "      <th>DEEP_CHANNELS_202202</th>\n",
       "      <th>...</th>\n",
       "      <th>AMP_202203</th>\n",
       "      <th>AMP_202204</th>\n",
       "      <th>AMP_202205</th>\n",
       "      <th>AMP_202206</th>\n",
       "      <th>NUM_TRANSACTIONS_202201</th>\n",
       "      <th>NUM_TRANSACTIONS_202202</th>\n",
       "      <th>NUM_TRANSACTIONS_202203</th>\n",
       "      <th>NUM_TRANSACTIONS_202204</th>\n",
       "      <th>NUM_TRANSACTIONS_202205</th>\n",
       "      <th>NUM_TRANSACTIONS_202206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>ZWZZ!W</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>&amp;WXYY&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Y%@YZ&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>!W%&amp;#!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>%##AXY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREDIT_UNION_ID ACCOUNT_NUM  FLG_202201  FLG_202202  FLG_202203  FLG_202204  \\\n",
       "0               A      ZWZZ!W           1           1           1           1   \n",
       "1               A      &WXYY&           1           1           1           1   \n",
       "2               A      Y%@YZ&           1           1           1           1   \n",
       "3               A      !W%&#!           1           1           1           1   \n",
       "4               A      %##AXY           1           1           1           1   \n",
       "\n",
       "   FLG_202205  FLG_202206  DEEP_CHANNELS_202201  DEEP_CHANNELS_202202  ...  \\\n",
       "0           1           1                     0                     0  ...   \n",
       "1           1           1                     0                     0  ...   \n",
       "2           1           1                     0                     0  ...   \n",
       "3           1           1                     0                     0  ...   \n",
       "4           1           1                     0                     0  ...   \n",
       "\n",
       "   AMP_202203  AMP_202204  AMP_202205  AMP_202206  NUM_TRANSACTIONS_202201  \\\n",
       "0           3           3           2           4                       68   \n",
       "1           1           2           2           1                       14   \n",
       "2           2           2           1           2                       12   \n",
       "3           3           3           2           2                       38   \n",
       "4           3           2           3           2                       24   \n",
       "\n",
       "   NUM_TRANSACTIONS_202202  NUM_TRANSACTIONS_202203  NUM_TRANSACTIONS_202204  \\\n",
       "0                       86                      130                      100   \n",
       "1                        8                        4                       24   \n",
       "2                        6                       10                       12   \n",
       "3                       24                       36                       54   \n",
       "4                       12                       12                        8   \n",
       "\n",
       "   NUM_TRANSACTIONS_202205  NUM_TRANSACTIONS_202206  \n",
       "0                       68                      112  \n",
       "1                       12                       10  \n",
       "2                       12                       20  \n",
       "3                       72                       48  \n",
       "4                        6                       20  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Model Data Set (pseudo).csv',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d114e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91848, 68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3853474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make sure to create a copy of the data before we start altering it. Note that we don't change the original data we loaded.\n",
    "data = df.copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac166679",
   "metadata": {},
   "source": [
    "# Preparing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672f29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare independent variables (X) and dependent variable (y)\n",
    "\n",
    "# To avoid writing them out every time, we save the names of the estimators of our model in a list. \n",
    "independent_variables=[#PIX\n",
    "            'DEEP_PIX_202201',\n",
    "            'DEEP_PIX_202202',\n",
    "            'DEEP_PIX_202203',\n",
    "            'DEEP_PIX_202204',\n",
    "            'DEEP_PIX_202205',\n",
    "            #BILLS\n",
    "            'DEEP_BILLS_202201',\n",
    "            'DEEP_BILLS_202202',\n",
    "            'DEEP_BILLS_202203',\n",
    "            'DEEP_BILLS_202204',\n",
    "            'DEEP_BILLS_202205',\n",
    "            #CARDS\n",
    "            'DEEP_CARDS_202201',\n",
    "            'DEEP_CARDS_202202',\n",
    "            'DEEP_CARDS_202203',\n",
    "            'DEEP_CARDS_202204',\n",
    "            'DEEP_CARDS_202205',\n",
    "            #CHECKING\n",
    "            'DEEP_CHECKING_202201',\n",
    "            'DEEP_CHECKING_202202',\n",
    "            'DEEP_CHECKING_202203',\n",
    "            'DEEP_CHECKING_202204',\n",
    "            'DEEP_CHECKING_202205',\n",
    "            #CREDIT\n",
    "            'DEEP_CREDIT_202201',\n",
    "            'DEEP_CREDIT_202202',\n",
    "            'DEEP_CREDIT_202203',\n",
    "            'DEEP_CREDIT_202204',\n",
    "            'DEEP_CREDIT_202205',\n",
    "            #INVESTMENTS\n",
    "            'DEEP_INVESTMENTS_202201',\n",
    "            'DEEP_INVESTMENTS_202202',\n",
    "            'DEEP_INVESTMENTS_202203',\n",
    "            'DEEP_INVESTMENTS_202204',\n",
    "            'DEEP_INVESTMENTS_202205',\n",
    "            #PAYMENTS\n",
    "            'DEEP_PAYMENTS_202201',\n",
    "            'DEEP_PAYMENTS_202202',\n",
    "            'DEEP_PAYMENTS_202203',\n",
    "            'DEEP_PAYMENTS_202204',\n",
    "            'DEEP_PAYMENTS_202205',\n",
    "            #AMPLITUDE\n",
    "            'AMP_202201',\n",
    "            'AMP_202202',\n",
    "            'AMP_202203',\n",
    "            'AMP_202204',\n",
    "            'AMP_202205'\n",
    "           ]\n",
    "\n",
    "X = data[independent_variables]\n",
    "y = data['FLG_202206']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56850fdd",
   "metadata": {},
   "source": [
    "# Handling class imbalance\n",
    "\n",
    "We know from our exploratory analysis that this dataset will be havily imbalanced with churn on 6th month as the minority class (represented as inactivity on that month or FLG_202206 = 0).\n",
    "\n",
    "The problem with classifiers and class imbalance is that the classifier will more easily classify the majority class, simply because most cases are of that class. For that reason model performance metrics have to be carefully selected. Precision, recall and F1 will be used as the main metrics for evaluating performance. In our specfic case we our most interested in those metrics regarding the prediction of the minority class (0 in our case).\n",
    "\n",
    "So in this study we will contrast the use of two wildly used classification models: Logistic Regression and RandomTreeClassifier, both with SciKit Learn implementations. Tree Ensembles our suposabily better at handling inbalance. And a common technique for getting better results is using resampling techniques. For that we will contrast model metrics on baseline models with resampled models (RandomOverSampling, SMOTE and NearMisses)\n",
    "\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://medium.com/grabngoinfo/four-oversampling-and-under-sampling-methods-for-imbalanced-classification-using-python-7304aedf9037\n",
    "\n",
    "https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcc6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the modeling dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Model and performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, classification_report, confusion_matrix  \n",
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter\n",
    "# Processing time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab435845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model_name,resampling_name,y_test,model_prediction,verbose):\n",
    "    \"\"\"\n",
    "    Prints the performance reports: Classification report and Confusion Matrix\n",
    "    \n",
    "    Inputs\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling method\n",
    "    y_test = Test vector\n",
    "    model_prediction = Prediction vector\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    Returns print with the reports\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    cr = classification_report(y_test, model_prediction)\n",
    "    cm = confusion_matrix(y_test, model_prediction)\n",
    "    print('\\n',model_name,'with',resampling_name,' Classification Report:')\n",
    "    print(cr)\n",
    "    print(cm)\n",
    "    \n",
    "    if verbose != 'off': print(\"\\nModel Performane processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    return cr,cm\n",
    "    \n",
    "    # #Precision-Recall Curve gives us the correct accuracy in this imbalanced dataset case. We can see that we have a very poor accuracy for the model.\n",
    "    # precision, recall, thresholds = precision_recall_curve(model_prediction, y_test)\n",
    "\n",
    "    # # create plot\n",
    "    # plt.plot(precision, recall, label='Precision-recall curve')\n",
    "    # plt.xlabel('Precision')\n",
    "    # plt.ylabel('Recall')\n",
    "    # plt.title('Precision-recall curve')\n",
    "    # plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae27bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_resample_sets(model_name,resampling_name,X,y,test_size,random_state,verbose):\n",
    "    \"\"\"\n",
    "    Splits and resamples X dataset and y vector.\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling method\n",
    "    X = DataFrame with independent variables\n",
    "    y = Vector with dependent (response) variable\n",
    "    test_size = Float (0 to 1) for test size porcentage of the train/test split\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    X_train = DataFrame with independent variables splitted for train set\n",
    "    X_test = DataFrame with independent variables splitted for test set\n",
    "    y_train = Vector with dependent variable splitted for train set\n",
    "    y_test = Vector with dependent variable splitted for test set\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    if verbose != 'off': print('\\nIniatialing split for train and test sets. \\nAnalyzing need for variable rescaling.')\n",
    "    if model_name == 'Logistic Regression':\n",
    "        if verbose != 'off': print('\\nLogistic Regression requies scaling. \\nVariable rescaling necessary.')\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_scaled\n",
    "\n",
    "        # Split into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,test_size = test_size, random_state = random_state)\n",
    "    elif model_name == 'Random Forest':\n",
    "        if verbose != 'off': print('\\nRandom Forest does not require rescalling.')\n",
    "        # Split into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    if verbose != 'off': print('\\nApplying resampling technique choosen.')\n",
    "    if resampling_name == 'Baseline':\n",
    "        if verbose != 'off': print(\"\\nBaseline doesn't require resampling.\")\n",
    "    elif resampling_name == 'Random Over Sampling':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = RandomOverSampler(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'SMOTE':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = SMOTE(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'NearMiss KNN':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = NearMiss(version=3,random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    elif resampling_name == 'Random Under Sampling':\n",
    "        if verbose != 'off': print('\\nApplying',resampling_name)\n",
    "        resampler = RandomUnderSampler(random_state=random_state)\n",
    "        X_train, y_train= resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    if verbose != 'off': print(\"\\nResampling processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7485c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(model_name,random_state,verbose):\n",
    "    \"\"\"\n",
    "    Instantiates and defines Classifier models.\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    Returns intantiated model according to users choice.\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    if verbose != 'off': print('\\nInstantiating',model_name,'model.')\n",
    "    rf = RandomForestClassifier(random_state = random_state,\n",
    "                                class_weight='balanced'\n",
    "                               )\n",
    "    lr =  LogisticRegression(random_state = random_state,\n",
    "                             class_weight='balanced',\n",
    "                             penalty = 'l2'\n",
    "                            )\n",
    "    if model_name == 'Random Forest':\n",
    "        if verbose != 'off': print('\\nModel ready:',rf)\n",
    "        if verbose != 'off': print(\"Model Instatiating processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        return rf\n",
    "    elif model_name == 'Logistic Regression':\n",
    "        if verbose != 'off': print('\\nModel ready:',lr)\n",
    "        if verbose != 'off': print(\"Model Instatiating processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        return lr\n",
    "    else:\n",
    "        print('\\nNo compatible model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c742e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model_name,resampling_name,X,y,random_state,test_size,verbose):\n",
    "    \"\"\"\n",
    "    Trains and Fits Models with different Resampling Techniques\n",
    "    \n",
    "    INPUT\n",
    "    model_name = Str with model name\n",
    "    resampling_name = Str with resampling technique name\n",
    "    X = DataFrame with independent variables\n",
    "    y = Vector with dependent (response) variable\n",
    "    random_state = INT random state number\n",
    "    verbose = STR to switch execution log on or off\n",
    "    \n",
    "    OUTPUT\n",
    "    model_prediction = Vector with chosen model with resampling predictions on the test set\n",
    "    \"\"\"\n",
    "    start_time = time.time() #Count processing time\n",
    "    print('\\n--------------------------------------------------------------------------------\\n--------------------------------------------------------------------------------')\n",
    "    if verbose != 'off': print('\\nStarting new sequence:',model_name,'with',resampling_name)\n",
    "    model_prediction = []\n",
    "    y_train_resampled = []  \n",
    " \n",
    "    \n",
    "    #Define model\n",
    "    model = define_model(model_name,random_state,verbose)\n",
    "    #Split train and test sets + Apply scaling when need + Apply resampling\n",
    "    X_train, X_test, y_train, y_test = split_resample_sets(model_name,resampling_name,X,y,test_size,random_state,verbose)\n",
    "    #Train model\n",
    "    if verbose != 'off': print('\\nFitting model.')\n",
    "    model = model.fit(X_train, y_train)\n",
    "    if verbose != 'off': print(\"\\nFitting model processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    #Predict on trained model\n",
    "    if verbose != 'off': print('\\nPredicting on model.')\n",
    "    model_prediction = model.predict(X_test) \n",
    "    if verbose != 'off': print(\"\\nModel prediction processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    #Evaluate model performance   \n",
    "    cr,cm = model_performance(model_name,resampling_name,y_test,model_prediction,verbose)\n",
    "    \n",
    "    print(\"\\nTotal processing time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return model,cr,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f3e7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Coef_Table(model_prediction):\n",
    "    \"\"\"\n",
    "    Function for analyzing the different importance coefients of both Logistic Regression and Random Forest models.\n",
    "    Prints out a table and bar graph of the top 10 coeficients (simple summ)\n",
    "    \n",
    "    INPUT\n",
    "    model_prediction = List containing the outputs of model_predict function:\n",
    "                            model = Class Fitted Classfier model instances (Logistic Regression or Ranfom Forest)\n",
    "                            cr = Str Classification Report\n",
    "                            cm = NP.Array Confusion Matrix\n",
    "                            model_name = Str with model name\n",
    "                            resampling_name = Str with resampling technique name\n",
    "    OUTPUT\n",
    "    Model_Coef_Table = Pandas Dataframe with Features and Coefients\n",
    "                            \n",
    "    \"\"\"\n",
    "    i=1\n",
    "    Model_Coef_Table = pd.DataFrame()\n",
    "    Model_Coef_Table['Features'] = X.columns\n",
    "    Model_Coef_Table['Coef'] = 0\n",
    "    for entry in model_prediction:\n",
    "        model = entry[0] #Model\n",
    "        cr = entry[1] #Classification Report\n",
    "        cm = entry[2] #Confusion Matrix\n",
    "        model_name = entry[3] #Model Name\n",
    "        resampler_name = entry[4] #Resampler Name\n",
    "\n",
    "    #     print('\\n'+model_name+resampler_name+'\\n')\n",
    "        if model_name == 'Random Forest':\n",
    "            importance = pd.DataFrame()\n",
    "            importance['Coef'] = model.feature_importances_\n",
    "            importance['Features'] = X.columns\n",
    "            importance = importance.sort_values(by=['Coef'],ascending=False)\n",
    "\n",
    "            Model_Coef_Table['Features'+model_name] = importance['Features']\n",
    "            Model_Coef_Table['Coef'+model_name] = importance['Coef']\n",
    "            Model_Coef_Table['Coef'] = importance['Coef'] + importance['Coef']\n",
    "\n",
    "        elif model_name == 'Logistic Regression':\n",
    "            importance = pd.DataFrame()\n",
    "            importance['Coef'] = model.coef_[0]\n",
    "            importance['Features'] = X.columns\n",
    "            importance = importance.sort_values(by=['Coef'],ascending=False)\n",
    "\n",
    "            Model_Coef_Table['Features'+model_name] = importance['Features']\n",
    "            Model_Coef_Table['Coef'+model_name] = importance['Coef']\n",
    "            Model_Coef_Table['Coef'] = importance['Coef'] + importance['Coef']\n",
    "\n",
    "        i= i+1\n",
    "\n",
    "\n",
    "    Model_Coef_Table['Coef_Avg'] = Model_Coef_Table['Coef'] / (i-1)\n",
    "    Model_Coef_Table = Model_Coef_Table.sort_values(by=['Coef'],ascending=False)\n",
    "    #print(Model_Coef_Table[['Features','Coef','Coef_Avg']][:5])\n",
    "\n",
    "\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.barh(Model_Coef_Table['Features'][:10],Model_Coef_Table['Coef_Avg'][:10])\n",
    "    \n",
    "    return Model_Coef_Table, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bbdcf",
   "metadata": {},
   "source": [
    "## Processing and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e83623c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.53      0.50      0.50     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    5   418]\n",
      " [   54 13301]]\n",
      "\n",
      "Total processing time: --- 9.524834871292114 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.02      0.03       423\n",
      "           1       0.97      0.99      0.98     13355\n",
      "\n",
      "    accuracy                           0.96     13778\n",
      "   macro avg       0.53      0.51      0.51     13778\n",
      "weighted avg       0.94      0.96      0.95     13778\n",
      "\n",
      "[[    9   414]\n",
      " [   89 13266]]\n",
      "\n",
      "Total processing time: --- 26.73296284675598 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.14      0.14       423\n",
      "           1       0.97      0.97      0.97     13355\n",
      "\n",
      "    accuracy                           0.95     13778\n",
      "   macro avg       0.55      0.56      0.55     13778\n",
      "weighted avg       0.95      0.95      0.95     13778\n",
      "\n",
      "[[   60   363]\n",
      " [  391 12964]]\n",
      "\n",
      "Total processing time: --- 27.69455623626709 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02       423\n",
      "           1       0.97      1.00      0.98     13355\n",
      "\n",
      "    accuracy                           0.97     13778\n",
      "   macro avg       0.53      0.50      0.50     13778\n",
      "weighted avg       0.94      0.97      0.95     13778\n",
      "\n",
      "[[    5   418]\n",
      " [   54 13301]]\n",
      "\n",
      "Total processing time: --- 10.390007734298706 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.77      0.16       423\n",
      "           1       0.99      0.75      0.85     13355\n",
      "\n",
      "    accuracy                           0.75     13778\n",
      "   macro avg       0.54      0.76      0.51     13778\n",
      "weighted avg       0.96      0.75      0.83     13778\n",
      "\n",
      "[[  327    96]\n",
      " [ 3337 10018]]\n",
      "\n",
      "Total processing time: --- 0.8430156707763672 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 358   65]\n",
      " [4030 9325]]\n",
      "\n",
      "Total processing time: --- 0.4431469440460205 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 358   65]\n",
      " [4032 9323]]\n",
      "\n",
      "Total processing time: --- 1.1570746898651123 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.83      0.15       423\n",
      "           1       0.99      0.71      0.83     13355\n",
      "\n",
      "    accuracy                           0.71     13778\n",
      "   macro avg       0.54      0.77      0.49     13778\n",
      "weighted avg       0.96      0.71      0.81     13778\n",
      "\n",
      "[[ 353   70]\n",
      " [3864 9491]]\n",
      "\n",
      "Total processing time: --- 1.3063278198242188 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 358   65]\n",
      " [4030 9325]]\n",
      "\n",
      "Total processing time: --- 0.4864814281463623 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.85      0.15       423\n",
      "           1       0.99      0.70      0.82     13355\n",
      "\n",
      "    accuracy                           0.70     13778\n",
      "   macro avg       0.54      0.77      0.48     13778\n",
      "weighted avg       0.97      0.70      0.80     13778\n",
      "\n",
      "[[ 359   64]\n",
      " [4062 9293]]\n",
      "\n",
      "Total processing time: --- 0.21437621116638184 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#set shared variables\n",
    "random_state = 26\n",
    "test_size = 0.15\n",
    "#set model names\n",
    "models = ['Random Forest',\n",
    "          'Logistic Regression',\n",
    "         ]\n",
    "#set resampling names\n",
    "resamplers = [\n",
    "              'Baseline',\n",
    "              'Random Over Sampling',\n",
    "              'SMOTE',\n",
    "              'Near Miss KNN',\n",
    "              'Random Under Sampling',\n",
    "             ]\n",
    "\n",
    "#Instantiate empy models\n",
    "model_prediction = []\n",
    "\n",
    "for model_name in models:\n",
    "    for resampler_name in resamplers:\n",
    "        model,cr,cm = model_predict(model_name,resampler_name,X,y,random_state,test_size,'off')\n",
    "        model_prediction.append((model,cr,cm,model_name,resampler_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cefa28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Features      Coef  Coef_Avg\n",
      "4        DEEP_PIX_202205  5.190888  0.519089\n",
      "34  DEEP_PAYMENTS_202205  1.695646  0.169565\n",
      "39            AMP_202205  1.026318  0.102632\n",
      "9      DEEP_BILLS_202205  0.967727  0.096773\n",
      "36            AMP_202202  0.530664  0.053066\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coef</th>\n",
       "      <th>FeaturesRandom Forest</th>\n",
       "      <th>CoefRandom Forest</th>\n",
       "      <th>FeaturesLogistic Regression</th>\n",
       "      <th>CoefLogistic Regression</th>\n",
       "      <th>Coef_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEEP_PIX_202205</td>\n",
       "      <td>5.190888</td>\n",
       "      <td>DEEP_PIX_202205</td>\n",
       "      <td>0.150976</td>\n",
       "      <td>DEEP_PIX_202205</td>\n",
       "      <td>2.595444</td>\n",
       "      <td>0.519089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DEEP_PAYMENTS_202205</td>\n",
       "      <td>1.695646</td>\n",
       "      <td>DEEP_PAYMENTS_202205</td>\n",
       "      <td>0.054880</td>\n",
       "      <td>DEEP_PAYMENTS_202205</td>\n",
       "      <td>0.847823</td>\n",
       "      <td>0.169565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AMP_202205</td>\n",
       "      <td>1.026318</td>\n",
       "      <td>AMP_202205</td>\n",
       "      <td>0.077617</td>\n",
       "      <td>AMP_202205</td>\n",
       "      <td>0.513159</td>\n",
       "      <td>0.102632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEEP_BILLS_202205</td>\n",
       "      <td>0.967727</td>\n",
       "      <td>DEEP_BILLS_202205</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>DEEP_BILLS_202205</td>\n",
       "      <td>0.483864</td>\n",
       "      <td>0.096773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AMP_202202</td>\n",
       "      <td>0.530664</td>\n",
       "      <td>AMP_202202</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>AMP_202202</td>\n",
       "      <td>0.265332</td>\n",
       "      <td>0.053066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AMP_202204</td>\n",
       "      <td>0.397113</td>\n",
       "      <td>AMP_202204</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>AMP_202204</td>\n",
       "      <td>0.198556</td>\n",
       "      <td>0.039711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DEEP_CHECKING_202205</td>\n",
       "      <td>0.331202</td>\n",
       "      <td>DEEP_CHECKING_202205</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>DEEP_CHECKING_202205</td>\n",
       "      <td>0.165601</td>\n",
       "      <td>0.033120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEEP_BILLS_202204</td>\n",
       "      <td>0.252594</td>\n",
       "      <td>DEEP_BILLS_202204</td>\n",
       "      <td>0.019468</td>\n",
       "      <td>DEEP_BILLS_202204</td>\n",
       "      <td>0.126297</td>\n",
       "      <td>0.025259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DEEP_CARDS_202205</td>\n",
       "      <td>0.241974</td>\n",
       "      <td>DEEP_CARDS_202205</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>DEEP_CARDS_202205</td>\n",
       "      <td>0.120987</td>\n",
       "      <td>0.024197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AMP_202203</td>\n",
       "      <td>0.233947</td>\n",
       "      <td>AMP_202203</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>AMP_202203</td>\n",
       "      <td>0.116973</td>\n",
       "      <td>0.023395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DEEP_INVESTMENTS_202203</td>\n",
       "      <td>0.155175</td>\n",
       "      <td>DEEP_INVESTMENTS_202203</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>DEEP_INVESTMENTS_202203</td>\n",
       "      <td>0.077587</td>\n",
       "      <td>0.015517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DEEP_CREDIT_202205</td>\n",
       "      <td>0.154654</td>\n",
       "      <td>DEEP_CREDIT_202205</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>DEEP_CREDIT_202205</td>\n",
       "      <td>0.077327</td>\n",
       "      <td>0.015465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AMP_202201</td>\n",
       "      <td>0.149222</td>\n",
       "      <td>AMP_202201</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>AMP_202201</td>\n",
       "      <td>0.074611</td>\n",
       "      <td>0.014922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DEEP_INVESTMENTS_202201</td>\n",
       "      <td>0.136330</td>\n",
       "      <td>DEEP_INVESTMENTS_202201</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>DEEP_INVESTMENTS_202201</td>\n",
       "      <td>0.068165</td>\n",
       "      <td>0.013633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DEEP_INVESTMENTS_202205</td>\n",
       "      <td>0.129514</td>\n",
       "      <td>DEEP_INVESTMENTS_202205</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>DEEP_INVESTMENTS_202205</td>\n",
       "      <td>0.064757</td>\n",
       "      <td>0.012951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DEEP_CHECKING_202201</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>DEEP_CHECKING_202201</td>\n",
       "      <td>0.015255</td>\n",
       "      <td>DEEP_CHECKING_202201</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>0.003290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEEP_CREDIT_202202</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>DEEP_CREDIT_202202</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>DEEP_CREDIT_202202</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DEEP_PAYMENTS_202201</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>DEEP_PAYMENTS_202201</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>DEEP_PAYMENTS_202201</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>-0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DEEP_CHECKING_202203</td>\n",
       "      <td>-0.039424</td>\n",
       "      <td>DEEP_CHECKING_202203</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>DEEP_CHECKING_202203</td>\n",
       "      <td>-0.019712</td>\n",
       "      <td>-0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DEEP_PAYMENTS_202204</td>\n",
       "      <td>-0.043553</td>\n",
       "      <td>DEEP_PAYMENTS_202204</td>\n",
       "      <td>0.025297</td>\n",
       "      <td>DEEP_PAYMENTS_202204</td>\n",
       "      <td>-0.021777</td>\n",
       "      <td>-0.004355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DEEP_CHECKING_202204</td>\n",
       "      <td>-0.055089</td>\n",
       "      <td>DEEP_CHECKING_202204</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>DEEP_CHECKING_202204</td>\n",
       "      <td>-0.027544</td>\n",
       "      <td>-0.005509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEEP_CREDIT_202204</td>\n",
       "      <td>-0.077510</td>\n",
       "      <td>DEEP_CREDIT_202204</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>DEEP_CREDIT_202204</td>\n",
       "      <td>-0.038755</td>\n",
       "      <td>-0.007751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEEP_BILLS_202202</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>DEEP_BILLS_202202</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>DEEP_BILLS_202202</td>\n",
       "      <td>-0.062800</td>\n",
       "      <td>-0.012560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DEEP_CARDS_202204</td>\n",
       "      <td>-0.145511</td>\n",
       "      <td>DEEP_CARDS_202204</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>DEEP_CARDS_202204</td>\n",
       "      <td>-0.072756</td>\n",
       "      <td>-0.014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DEEP_INVESTMENTS_202202</td>\n",
       "      <td>-0.147151</td>\n",
       "      <td>DEEP_INVESTMENTS_202202</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>DEEP_INVESTMENTS_202202</td>\n",
       "      <td>-0.073575</td>\n",
       "      <td>-0.014715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DEEP_CREDIT_202201</td>\n",
       "      <td>-0.148844</td>\n",
       "      <td>DEEP_CREDIT_202201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>DEEP_CREDIT_202201</td>\n",
       "      <td>-0.074422</td>\n",
       "      <td>-0.014884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DEEP_CARDS_202201</td>\n",
       "      <td>-0.151591</td>\n",
       "      <td>DEEP_CARDS_202201</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>DEEP_CARDS_202201</td>\n",
       "      <td>-0.075795</td>\n",
       "      <td>-0.015159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEEP_BILLS_202203</td>\n",
       "      <td>-0.230671</td>\n",
       "      <td>DEEP_BILLS_202203</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>DEEP_BILLS_202203</td>\n",
       "      <td>-0.115335</td>\n",
       "      <td>-0.023067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEEP_CHECKING_202202</td>\n",
       "      <td>-0.233944</td>\n",
       "      <td>DEEP_CHECKING_202202</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>DEEP_CHECKING_202202</td>\n",
       "      <td>-0.116972</td>\n",
       "      <td>-0.023394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DEEP_CARDS_202202</td>\n",
       "      <td>-0.241468</td>\n",
       "      <td>DEEP_CARDS_202202</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>DEEP_CARDS_202202</td>\n",
       "      <td>-0.120734</td>\n",
       "      <td>-0.024147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DEEP_INVESTMENTS_202204</td>\n",
       "      <td>-0.254262</td>\n",
       "      <td>DEEP_INVESTMENTS_202204</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>DEEP_INVESTMENTS_202204</td>\n",
       "      <td>-0.127131</td>\n",
       "      <td>-0.025426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DEEP_CARDS_202203</td>\n",
       "      <td>-0.306628</td>\n",
       "      <td>DEEP_CARDS_202203</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>DEEP_CARDS_202203</td>\n",
       "      <td>-0.153314</td>\n",
       "      <td>-0.030663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEEP_PAYMENTS_202203</td>\n",
       "      <td>-0.322534</td>\n",
       "      <td>DEEP_PAYMENTS_202203</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>DEEP_PAYMENTS_202203</td>\n",
       "      <td>-0.161267</td>\n",
       "      <td>-0.032253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DEEP_CREDIT_202203</td>\n",
       "      <td>-0.325937</td>\n",
       "      <td>DEEP_CREDIT_202203</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>DEEP_CREDIT_202203</td>\n",
       "      <td>-0.162969</td>\n",
       "      <td>-0.032594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEEP_PIX_202201</td>\n",
       "      <td>-0.391128</td>\n",
       "      <td>DEEP_PIX_202201</td>\n",
       "      <td>0.055802</td>\n",
       "      <td>DEEP_PIX_202201</td>\n",
       "      <td>-0.195564</td>\n",
       "      <td>-0.039113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEEP_PIX_202202</td>\n",
       "      <td>-0.393518</td>\n",
       "      <td>DEEP_PIX_202202</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>DEEP_PIX_202202</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.039352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEEP_PIX_202204</td>\n",
       "      <td>-0.404263</td>\n",
       "      <td>DEEP_PIX_202204</td>\n",
       "      <td>0.073048</td>\n",
       "      <td>DEEP_PIX_202204</td>\n",
       "      <td>-0.202132</td>\n",
       "      <td>-0.040426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DEEP_PAYMENTS_202202</td>\n",
       "      <td>-0.409957</td>\n",
       "      <td>DEEP_PAYMENTS_202202</td>\n",
       "      <td>0.018166</td>\n",
       "      <td>DEEP_PAYMENTS_202202</td>\n",
       "      <td>-0.204979</td>\n",
       "      <td>-0.040996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEEP_BILLS_202201</td>\n",
       "      <td>-0.514218</td>\n",
       "      <td>DEEP_BILLS_202201</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>DEEP_BILLS_202201</td>\n",
       "      <td>-0.257109</td>\n",
       "      <td>-0.051422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEEP_PIX_202203</td>\n",
       "      <td>-0.631733</td>\n",
       "      <td>DEEP_PIX_202203</td>\n",
       "      <td>0.060874</td>\n",
       "      <td>DEEP_PIX_202203</td>\n",
       "      <td>-0.315867</td>\n",
       "      <td>-0.063173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features      Coef    FeaturesRandom Forest  \\\n",
       "4           DEEP_PIX_202205  5.190888          DEEP_PIX_202205   \n",
       "34     DEEP_PAYMENTS_202205  1.695646     DEEP_PAYMENTS_202205   \n",
       "39               AMP_202205  1.026318               AMP_202205   \n",
       "9         DEEP_BILLS_202205  0.967727        DEEP_BILLS_202205   \n",
       "36               AMP_202202  0.530664               AMP_202202   \n",
       "38               AMP_202204  0.397113               AMP_202204   \n",
       "19     DEEP_CHECKING_202205  0.331202     DEEP_CHECKING_202205   \n",
       "8         DEEP_BILLS_202204  0.252594        DEEP_BILLS_202204   \n",
       "14        DEEP_CARDS_202205  0.241974        DEEP_CARDS_202205   \n",
       "37               AMP_202203  0.233947               AMP_202203   \n",
       "27  DEEP_INVESTMENTS_202203  0.155175  DEEP_INVESTMENTS_202203   \n",
       "24       DEEP_CREDIT_202205  0.154654       DEEP_CREDIT_202205   \n",
       "35               AMP_202201  0.149222               AMP_202201   \n",
       "25  DEEP_INVESTMENTS_202201  0.136330  DEEP_INVESTMENTS_202201   \n",
       "29  DEEP_INVESTMENTS_202205  0.129514  DEEP_INVESTMENTS_202205   \n",
       "15     DEEP_CHECKING_202201  0.032905     DEEP_CHECKING_202201   \n",
       "21       DEEP_CREDIT_202202  0.003035       DEEP_CREDIT_202202   \n",
       "30     DEEP_PAYMENTS_202201 -0.005635     DEEP_PAYMENTS_202201   \n",
       "17     DEEP_CHECKING_202203 -0.039424     DEEP_CHECKING_202203   \n",
       "33     DEEP_PAYMENTS_202204 -0.043553     DEEP_PAYMENTS_202204   \n",
       "18     DEEP_CHECKING_202204 -0.055089     DEEP_CHECKING_202204   \n",
       "23       DEEP_CREDIT_202204 -0.077510       DEEP_CREDIT_202204   \n",
       "6         DEEP_BILLS_202202 -0.125601        DEEP_BILLS_202202   \n",
       "13        DEEP_CARDS_202204 -0.145511        DEEP_CARDS_202204   \n",
       "26  DEEP_INVESTMENTS_202202 -0.147151  DEEP_INVESTMENTS_202202   \n",
       "20       DEEP_CREDIT_202201 -0.148844       DEEP_CREDIT_202201   \n",
       "10        DEEP_CARDS_202201 -0.151591        DEEP_CARDS_202201   \n",
       "7         DEEP_BILLS_202203 -0.230671        DEEP_BILLS_202203   \n",
       "16     DEEP_CHECKING_202202 -0.233944     DEEP_CHECKING_202202   \n",
       "11        DEEP_CARDS_202202 -0.241468        DEEP_CARDS_202202   \n",
       "28  DEEP_INVESTMENTS_202204 -0.254262  DEEP_INVESTMENTS_202204   \n",
       "12        DEEP_CARDS_202203 -0.306628        DEEP_CARDS_202203   \n",
       "32     DEEP_PAYMENTS_202203 -0.322534     DEEP_PAYMENTS_202203   \n",
       "22       DEEP_CREDIT_202203 -0.325937       DEEP_CREDIT_202203   \n",
       "0           DEEP_PIX_202201 -0.391128          DEEP_PIX_202201   \n",
       "1           DEEP_PIX_202202 -0.393518          DEEP_PIX_202202   \n",
       "3           DEEP_PIX_202204 -0.404263          DEEP_PIX_202204   \n",
       "31     DEEP_PAYMENTS_202202 -0.409957     DEEP_PAYMENTS_202202   \n",
       "5         DEEP_BILLS_202201 -0.514218        DEEP_BILLS_202201   \n",
       "2           DEEP_PIX_202203 -0.631733          DEEP_PIX_202203   \n",
       "\n",
       "    CoefRandom Forest FeaturesLogistic Regression  CoefLogistic Regression  \\\n",
       "4            0.150976             DEEP_PIX_202205                 2.595444   \n",
       "34           0.054880        DEEP_PAYMENTS_202205                 0.847823   \n",
       "39           0.077617                  AMP_202205                 0.513159   \n",
       "9            0.042316           DEEP_BILLS_202205                 0.483864   \n",
       "36           0.027963                  AMP_202202                 0.265332   \n",
       "38           0.035980                  AMP_202204                 0.198556   \n",
       "19           0.016287        DEEP_CHECKING_202205                 0.165601   \n",
       "8            0.019468           DEEP_BILLS_202204                 0.126297   \n",
       "14           0.007765           DEEP_CARDS_202205                 0.120987   \n",
       "37           0.025754                  AMP_202203                 0.116973   \n",
       "27           0.007479     DEEP_INVESTMENTS_202203                 0.077587   \n",
       "24           0.002654          DEEP_CREDIT_202205                 0.077327   \n",
       "35           0.020324                  AMP_202201                 0.074611   \n",
       "25           0.007326     DEEP_INVESTMENTS_202201                 0.068165   \n",
       "29           0.007822     DEEP_INVESTMENTS_202205                 0.064757   \n",
       "15           0.015255        DEEP_CHECKING_202201                 0.016452   \n",
       "21           0.002199          DEEP_CREDIT_202202                 0.001517   \n",
       "30           0.019375        DEEP_PAYMENTS_202201                -0.002818   \n",
       "17           0.015694        DEEP_CHECKING_202203                -0.019712   \n",
       "33           0.025297        DEEP_PAYMENTS_202204                -0.021777   \n",
       "18           0.014608        DEEP_CHECKING_202204                -0.027544   \n",
       "23           0.002252          DEEP_CREDIT_202204                -0.038755   \n",
       "6            0.018118           DEEP_BILLS_202202                -0.062800   \n",
       "13           0.007241           DEEP_CARDS_202204                -0.072756   \n",
       "26           0.007025     DEEP_INVESTMENTS_202202                -0.073575   \n",
       "20           0.002088          DEEP_CREDIT_202201                -0.074422   \n",
       "10           0.006904           DEEP_CARDS_202201                -0.075795   \n",
       "7            0.017260           DEEP_BILLS_202203                -0.115335   \n",
       "16           0.013924        DEEP_CHECKING_202202                -0.116972   \n",
       "11           0.006617           DEEP_CARDS_202202                -0.120734   \n",
       "28           0.007868     DEEP_INVESTMENTS_202204                -0.127131   \n",
       "12           0.007490           DEEP_CARDS_202203                -0.153314   \n",
       "32           0.021554        DEEP_PAYMENTS_202203                -0.161267   \n",
       "22           0.003688          DEEP_CREDIT_202203                -0.162969   \n",
       "0            0.055802             DEEP_PIX_202201                -0.195564   \n",
       "1            0.054875             DEEP_PIX_202202                -0.196759   \n",
       "3            0.073048             DEEP_PIX_202204                -0.202132   \n",
       "31           0.018166        DEEP_PAYMENTS_202202                -0.204979   \n",
       "5            0.018165           DEEP_BILLS_202201                -0.257109   \n",
       "2            0.060874             DEEP_PIX_202203                -0.315867   \n",
       "\n",
       "    Coef_Avg  \n",
       "4   0.519089  \n",
       "34  0.169565  \n",
       "39  0.102632  \n",
       "9   0.096773  \n",
       "36  0.053066  \n",
       "38  0.039711  \n",
       "19  0.033120  \n",
       "8   0.025259  \n",
       "14  0.024197  \n",
       "37  0.023395  \n",
       "27  0.015517  \n",
       "24  0.015465  \n",
       "35  0.014922  \n",
       "25  0.013633  \n",
       "29  0.012951  \n",
       "15  0.003290  \n",
       "21  0.000303  \n",
       "30 -0.000564  \n",
       "17 -0.003942  \n",
       "33 -0.004355  \n",
       "18 -0.005509  \n",
       "23 -0.007751  \n",
       "6  -0.012560  \n",
       "13 -0.014551  \n",
       "26 -0.014715  \n",
       "20 -0.014884  \n",
       "10 -0.015159  \n",
       "7  -0.023067  \n",
       "16 -0.023394  \n",
       "11 -0.024147  \n",
       "28 -0.025426  \n",
       "12 -0.030663  \n",
       "32 -0.032253  \n",
       "22 -0.032594  \n",
       "0  -0.039113  \n",
       "1  -0.039352  \n",
       "3  -0.040426  \n",
       "31 -0.040996  \n",
       "5  -0.051422  \n",
       "2  -0.063173  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Model Coeficient Table\n",
    "Model_Coef_Table(model_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799bb3a",
   "metadata": {},
   "source": [
    "# Section 5: Evaluate the Results\n",
    "\n",
    "This section will split up into separate analyses for each business question.\n",
    "\n",
    "### Question 2: Are mono-product-family users more likely to have channel innactivity in a six month window?\n",
    "\n",
    "### Question 3: Can transactional data alone safely predict channel innactivity in a six month window?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11153e71",
   "metadata": {},
   "source": [
    "## Question 1: What are aspects of a transactional dataset that can be used for understanding channel innactivity in a six month window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5bf2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare independent variables (X) and dependent variable (y)\n",
    "\n",
    "# To avoid writing them out every time, we save the names of the estimators of our model in a list. \n",
    "independent_variables=[#PIX\n",
    "#             'DEEP_PIX_202201',\n",
    "#             'DEEP_PIX_202202',\n",
    "#             'DEEP_PIX_202203',\n",
    "#             'DEEP_PIX_202204',\n",
    "            'DEEP_PIX_202205',\n",
    "            #BILLS\n",
    "#             'DEEP_BILLS_202201',\n",
    "#             'DEEP_BILLS_202202',\n",
    "#             'DEEP_BILLS_202203',\n",
    "            'DEEP_BILLS_202204',\n",
    "            'DEEP_BILLS_202205',\n",
    "#             #CARDS\n",
    "#             'DEEP_CARDS_202201',\n",
    "#             'DEEP_CARDS_202202',\n",
    "#             'DEEP_CARDS_202203',\n",
    "#             'DEEP_CARDS_202204',\n",
    "            'DEEP_CARDS_202205',\n",
    "#             #CHECKING\n",
    "#             'DEEP_CHECKING_202201',\n",
    "#             'DEEP_CHECKING_202202',\n",
    "#             'DEEP_CHECKING_202203',\n",
    "#             'DEEP_CHECKING_202204',\n",
    "            'DEEP_CHECKING_202205',\n",
    "#             #CREDIT\n",
    "#             'DEEP_CREDIT_202201',\n",
    "#             'DEEP_CREDIT_202202',\n",
    "#             'DEEP_CREDIT_202203',\n",
    "#             'DEEP_CREDIT_202204',\n",
    "#             'DEEP_CREDIT_202205',\n",
    "#             #INVESTMENTS\n",
    "#             'DEEP_INVESTMENTS_202201',\n",
    "#             'DEEP_INVESTMENTS_202202',\n",
    "#             'DEEP_INVESTMENTS_202203',\n",
    "#             'DEEP_INVESTMENTS_202204',\n",
    "#             'DEEP_INVESTMENTS_202205',\n",
    "#             #PAYMENTS\n",
    "#             'DEEP_PAYMENTS_202201',\n",
    "#             'DEEP_PAYMENTS_202202',\n",
    "#             'DEEP_PAYMENTS_202203',\n",
    "#             'DEEP_PAYMENTS_202204',\n",
    "            'DEEP_PAYMENTS_202205',\n",
    "#             #AMPLITUDE\n",
    "#             'AMP_202201',\n",
    "            'AMP_202202',\n",
    "            'AMP_202203',\n",
    "            'AMP_202204',\n",
    "            'AMP_202205'\n",
    "           ]\n",
    "\n",
    "X1 = data[independent_variables]\n",
    "y1 = data['FLG_202206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acce2673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.38      0.17       423\n",
      "           1       0.98      0.90      0.94     13355\n",
      "\n",
      "    accuracy                           0.88     13778\n",
      "   macro avg       0.54      0.64      0.55     13778\n",
      "weighted avg       0.95      0.88      0.91     13778\n",
      "\n",
      "[[  162   261]\n",
      " [ 1337 12018]]\n",
      "\n",
      "Total processing time: --- 4.5156090259552 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.41      0.16       423\n",
      "           1       0.98      0.88      0.93     13355\n",
      "\n",
      "    accuracy                           0.87     13778\n",
      "   macro avg       0.54      0.65      0.54     13778\n",
      "weighted avg       0.95      0.87      0.90     13778\n",
      "\n",
      "[[  175   248]\n",
      " [ 1601 11754]]\n",
      "\n",
      "Total processing time: --- 9.19087815284729 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.48      0.16       423\n",
      "           1       0.98      0.86      0.92     13355\n",
      "\n",
      "    accuracy                           0.85     13778\n",
      "   macro avg       0.54      0.67      0.54     13778\n",
      "weighted avg       0.95      0.85      0.89     13778\n",
      "\n",
      "[[  204   219]\n",
      " [ 1887 11468]]\n",
      "\n",
      "Total processing time: --- 9.37999153137207 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.38      0.17       423\n",
      "           1       0.98      0.90      0.94     13355\n",
      "\n",
      "    accuracy                           0.88     13778\n",
      "   macro avg       0.54      0.64      0.55     13778\n",
      "weighted avg       0.95      0.88      0.91     13778\n",
      "\n",
      "[[  162   261]\n",
      " [ 1337 12018]]\n",
      "\n",
      "Total processing time: --- 4.262848854064941 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Random Forest with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.75      0.14       423\n",
      "           1       0.99      0.73      0.84     13355\n",
      "\n",
      "    accuracy                           0.73     13778\n",
      "   macro avg       0.53      0.74      0.49     13778\n",
      "weighted avg       0.96      0.73      0.82     13778\n",
      "\n",
      "[[ 316  107]\n",
      " [3623 9732]]\n",
      "\n",
      "Total processing time: --- 0.5796682834625244 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Baseline  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.84      0.14       423\n",
      "           1       0.99      0.68      0.81     13355\n",
      "\n",
      "    accuracy                           0.69     13778\n",
      "   macro avg       0.54      0.76      0.48     13778\n",
      "weighted avg       0.96      0.69      0.79     13778\n",
      "\n",
      "[[ 357   66]\n",
      " [4210 9145]]\n",
      "\n",
      "Total processing time: --- 0.15199637413024902 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Over Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.84      0.14       423\n",
      "           1       0.99      0.69      0.81     13355\n",
      "\n",
      "    accuracy                           0.69     13778\n",
      "   macro avg       0.54      0.76      0.48     13778\n",
      "weighted avg       0.96      0.69      0.79     13778\n",
      "\n",
      "[[ 357   66]\n",
      " [4202 9153]]\n",
      "\n",
      "Total processing time: --- 0.2923009395599365 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with SMOTE  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.83      0.14       423\n",
      "           1       0.99      0.69      0.81     13355\n",
      "\n",
      "    accuracy                           0.69     13778\n",
      "   macro avg       0.54      0.76      0.48     13778\n",
      "weighted avg       0.96      0.69      0.79     13778\n",
      "\n",
      "[[ 352   71]\n",
      " [4154 9201]]\n",
      "\n",
      "Total processing time: --- 0.4051673412322998 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Near Miss KNN  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.84      0.14       423\n",
      "           1       0.99      0.68      0.81     13355\n",
      "\n",
      "    accuracy                           0.69     13778\n",
      "   macro avg       0.54      0.76      0.48     13778\n",
      "weighted avg       0.96      0.69      0.79     13778\n",
      "\n",
      "[[ 357   66]\n",
      " [4210 9145]]\n",
      "\n",
      "Total processing time: --- 0.1688981056213379 seconds ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Logistic Regression with Random Under Sampling  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.84      0.14       423\n",
      "           1       0.99      0.68      0.81     13355\n",
      "\n",
      "    accuracy                           0.69     13778\n",
      "   macro avg       0.54      0.76      0.48     13778\n",
      "weighted avg       0.96      0.69      0.79     13778\n",
      "\n",
      "[[ 357   66]\n",
      " [4239 9116]]\n",
      "\n",
      "Total processing time: --- 0.08975529670715332 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#set shared variables\n",
    "random_state = 26\n",
    "test_size = 0.15\n",
    "#set model names\n",
    "models = ['Random Forest',\n",
    "          'Logistic Regression',\n",
    "         ]\n",
    "#set resampling names\n",
    "resamplers = [\n",
    "              'Baseline',\n",
    "              'Random Over Sampling',\n",
    "              'SMOTE',\n",
    "              'Near Miss KNN',\n",
    "              'Random Under Sampling',\n",
    "             ]\n",
    "\n",
    "#Instantiate empy models\n",
    "model_prediction_revisited = []\n",
    "\n",
    "for model_name in models:\n",
    "    for resampler_name in resamplers:\n",
    "        model,cr,cm = model_predict(model_name,resampler_name,X1,y1,random_state,test_size,'off')\n",
    "        model_prediction.append((model,cr,cm,model_name,resampler_name))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca4f45fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Features  Coef  Coef_Avg\n",
      "0      DEEP_PIX_202201     0       NaN\n",
      "1      DEEP_PIX_202202     0       NaN\n",
      "22  DEEP_CREDIT_202203     0       NaN\n",
      "23  DEEP_CREDIT_202204     0       NaN\n",
      "24  DEEP_CREDIT_202205     0       NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Coef_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEEP_PIX_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEEP_PIX_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DEEP_CREDIT_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEEP_CREDIT_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DEEP_CREDIT_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DEEP_INVESTMENTS_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DEEP_INVESTMENTS_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DEEP_INVESTMENTS_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DEEP_INVESTMENTS_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DEEP_INVESTMENTS_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DEEP_PAYMENTS_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DEEP_PAYMENTS_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEEP_PAYMENTS_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DEEP_PAYMENTS_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DEEP_PAYMENTS_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AMP_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AMP_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AMP_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AMP_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEEP_CREDIT_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DEEP_CREDIT_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DEEP_CHECKING_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEEP_BILLS_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEEP_PIX_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEEP_PIX_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEEP_PIX_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEEP_BILLS_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEEP_BILLS_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEEP_BILLS_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEEP_BILLS_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DEEP_CARDS_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DEEP_CHECKING_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DEEP_CARDS_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DEEP_CARDS_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DEEP_CARDS_202204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DEEP_CARDS_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DEEP_CHECKING_202201</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEEP_CHECKING_202202</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DEEP_CHECKING_202203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AMP_202205</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Coef  Coef_Avg\n",
       "0           DEEP_PIX_202201     0       NaN\n",
       "1           DEEP_PIX_202202     0       NaN\n",
       "22       DEEP_CREDIT_202203     0       NaN\n",
       "23       DEEP_CREDIT_202204     0       NaN\n",
       "24       DEEP_CREDIT_202205     0       NaN\n",
       "25  DEEP_INVESTMENTS_202201     0       NaN\n",
       "26  DEEP_INVESTMENTS_202202     0       NaN\n",
       "27  DEEP_INVESTMENTS_202203     0       NaN\n",
       "28  DEEP_INVESTMENTS_202204     0       NaN\n",
       "29  DEEP_INVESTMENTS_202205     0       NaN\n",
       "30     DEEP_PAYMENTS_202201     0       NaN\n",
       "31     DEEP_PAYMENTS_202202     0       NaN\n",
       "32     DEEP_PAYMENTS_202203     0       NaN\n",
       "33     DEEP_PAYMENTS_202204     0       NaN\n",
       "34     DEEP_PAYMENTS_202205     0       NaN\n",
       "35               AMP_202201     0       NaN\n",
       "36               AMP_202202     0       NaN\n",
       "37               AMP_202203     0       NaN\n",
       "38               AMP_202204     0       NaN\n",
       "21       DEEP_CREDIT_202202     0       NaN\n",
       "20       DEEP_CREDIT_202201     0       NaN\n",
       "19     DEEP_CHECKING_202205     0       NaN\n",
       "9         DEEP_BILLS_202205     0       NaN\n",
       "2           DEEP_PIX_202203     0       NaN\n",
       "3           DEEP_PIX_202204     0       NaN\n",
       "4           DEEP_PIX_202205     0       NaN\n",
       "5         DEEP_BILLS_202201     0       NaN\n",
       "6         DEEP_BILLS_202202     0       NaN\n",
       "7         DEEP_BILLS_202203     0       NaN\n",
       "8         DEEP_BILLS_202204     0       NaN\n",
       "10        DEEP_CARDS_202201     0       NaN\n",
       "18     DEEP_CHECKING_202204     0       NaN\n",
       "11        DEEP_CARDS_202202     0       NaN\n",
       "12        DEEP_CARDS_202203     0       NaN\n",
       "13        DEEP_CARDS_202204     0       NaN\n",
       "14        DEEP_CARDS_202205     0       NaN\n",
       "15     DEEP_CHECKING_202201     0       NaN\n",
       "16     DEEP_CHECKING_202202     0       NaN\n",
       "17     DEEP_CHECKING_202203     0       NaN\n",
       "39               AMP_202205     0       NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAGdCAYAAAB6jTkMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZm0lEQVR4nO3deYxV5fnA8WeAGRCZGTc2dQStFrRqq9i6NGq1irhiSmJdimitYo1LNVHRmmI0Kq1GbaLVhqo00boCjf1D4gppZFwrlYA2sQWjBVwQZyYhVZD390d/3HKdeQbQGWD080luwj3nPee852XCfL0z91pTSikBAAAd6LW5JwAAwJZLLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAACpPpt7AvR8a9asiSVLlkR9fX3U1NRs7ukAABuglBJtbW2x4447Rq9e+euHYpEvbcmSJdHU1LS5pwEAfAHvvPNO7Lzzzul+sciXVl9fHxH//WJraGjYzLMBADZEa2trNDU1Vb6PZ8QiX9raHz03NDSIRQDoYdb3K2Te4AIAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABASiwCAJASiwAApMQiAAApsQgAQEosAgCQEosAAKTEIgAAKbEIAEBKLAIAkBKLAACkxCIAACmxCABAaqNi8ayzzoqampqoqamJ2traGDx4cBx99NFx7733xpo1ayrjhg8fXhm37mPKlCkREbF48eIO99fU1MQLL7wQERHTpk2r2j506NA45ZRTYtGiRRs013Xn0L9//9h7773j97//fWX/tGnTYptttqk8v+KKK2L48OHR1tZWdZ4TTzwxDjvssKr768hHH30UF110UYwYMSL69+8fu+yyS1x88cXR0tJSNW7FihUxfvz4aGxsjMbGxhg/fnx8/PHHlf1///vf47TTToumpqbYaqutYs8994zf/va3VeeYPXt2jB07NoYOHRpbb711fOc734kHHnig3ZzmzJkTo0aNin79+sVuu+0Wd999d9X+BQsWxLhx4yprdfvtt3d6jwDA189Gv7I4ZsyYWLp0aSxevDieeOKJOOKII+KSSy6JE044IVavXl0Zd91118XSpUurHhdddFHVuZ5++ul2Y0aNGlXZ39DQEEuXLo0lS5bEn/70p5g3b16cdNJJ8dlnn23QXNfO4fXXX4+TTz45zj///Hj44Yc7HHv99dfHgAED4rLLLqtsu/fee+O5556L++67L3r16nyplixZEkuWLIlbbrkl5s+fH9OmTYtZs2bFOeecUzXu9NNPj3nz5sWsWbNi1qxZMW/evBg/fnxl/6uvvhoDBw6M+++/PxYsWBC//OUv46qrroo77rijMmbu3Lmx7777xvTp0+P111+Pn/70p3HmmWfGX/7yl8qYRYsWxXHHHReHHnpovPbaa3H11VfHxRdfHNOnT6+MWblyZey2224xZcqUGDJkyAatKQDwNVM2woQJE8rYsWPbbX/mmWdKRJSpU6eWUkoZNmxYue2229LzLFq0qEREee2119Ix9913X2lsbKzadv/995eIKG+++eZ659rRHPbYY49y6qmnpud/5ZVXSm1tbXniiSfK22+/XRoaGsqdd9653mtlHnnkkVJXV1dWrVpVSill4cKFJSLKCy+8UBnT3Ny83nu64IILyhFHHNHptY477rhy9tlnV55fccUVZeTIkVVjJk6cWA466KAOj1/f31lnWlpaSkSUlpaWL3Q8ALDpbej37y75ncUjjzwyvv3tb8eMGTO64nSprbbaKiIiVq1a9YWO79evX6fHjho1Kq666qr42c9+FuPHj4/vfve78fOf//wLXSsioqWlJRoaGqJPnz4REdHc3ByNjY1x4IEHVsYcdNBB0djYGHPnzu30PNttt916r7XumObm5hg9enTVmGOOOSZeeeWVL7x+a33yySfR2tpa9QAAvpq67A0uI0eOjMWLF1eeX3nllTFgwICqx+zZs6uOOeSQQ9qNyX7E/O6778bNN98cO++8c3zzm9/cqLmtXr06pk2bFvPnz48f/vCHnY695pprolevXvHiiy/GvffeGzU1NRt1rbWWL18e119/fUycOLGybdmyZTFo0KB2YwcNGhTLli3r8DzNzc3xyCOPVJ3n8x577LF4+eWX4+yzz6661uDBg6vGDR48OFavXh0ffvjhxt5OlZtuuqnyO5eNjY3R1NT0pc4HAGy5+nTViUopVWF1+eWXx1lnnVU1Zqeddqp6/vDDD8eee+5Zta13796VP7e0tMSAAQOilBIrV66M/fffP2bMmBF1dXUbNKcrr7wyrrnmmvjkk0+irq4uLr/88k6jKyLiqaeeiqVLl0avXr3i5Zdfjl122WWDrrWu1tbWOP7442OvvfaKyZMnV+3rKD4/v3ZrLViwIMaOHRu/+tWv4uijj+7wWrNnz46zzjorpk6dGt/61rc6vVYpJZ3DxrjqqquqfreztbVVMALAV1SXxeIbb7wRu+66a+X5DjvsELvvvnunxzQ1NXU6pr6+Pv72t79Fr169YvDgwbH11ltv1JzWBmv//v1j6NCh642kFStWxLnnnhtXX3111NbWxgUXXBCHH3547LDDDht8zba2thgzZkwMGDAgZs6cGbW1tZV9Q4YMiffee6/dMR988EG7VwEXLlwYRx55ZJx77rlxzTXXdHitOXPmxIknnhi33nprnHnmmVX7hgwZ0u7Vyvfffz/69OkT22+//QbfT0f69u0bffv2/VLnAAB6hi75MfSzzz4b8+fPj3HjxnXF6Sp69eoVu+++e+y2224bHYoR/wvWHXfccYNeTbvoooti0KBBcc0118SkSZOiqakpLrzwwg2+Xmtra4wePTrq6uri8ccfj379+lXtP/jgg6OlpSVeeumlyrYXX3wxWlpa4pBDDqlsW7BgQRxxxBExYcKEuOGGGzq81uzZs+P444+PKVOmxHnnnddu/8EHHxxPPfVU1bYnn3wyDjjggKqABQDozEa/svjJJ5/EsmXL4rPPPov33nsvZs2aFTfddFOccMIJVa9utbW1tXtlq3///tHQ0FB5vnz58nZjttlmm3aRtSnMnDkzHn300Xj55ZcrMTVt2rQYNWpUTJ8+fb0h3NbWFqNHj46VK1fG/fffX/XGj4EDB0bv3r1jzz33jDFjxsS5555b+czH8847L0444YQYMWJERPwvFEePHh2XXXZZZX169+4dAwcOjIj/heIll1wS48aNq4ypq6urvMnl/PPPjzvuuCMuu+yyOPfcc6O5uTnuueeeePDBBytz/vTTT2PhwoWVP//73/+OefPmxYABA9b7qjAA8DWxMW+xnjBhQomIEhGlT58+ZeDAgeWoo44q9957b/nss88q44YNG1YZt+5j4sSJpZT/fXROR48HH3ywlNLxR9tsjPV9FMy65//ggw/KoEGDyg033NBu3A033FAGDRpUPvjgg06v99xzz6X3tGjRosq45cuXlzPOOKPU19eX+vr6csYZZ5QVK1ZU9k+ePLnDcwwbNqwyZt2/h3Ufhx9+eNWcZs+eXfbbb79SV1dXhg8fXu66666q/dnfw+fPsz4+OgcAep4N/f5dU8r/v+sBvqDW1tZobGysfFQQALDl29Dv3/7f0AAApHpkLD7wwAPtPp9x7ePzHx/Tk68JALC59cgfQ7e1tXX4ETQREbW1tTFs2LCvxDV7Cj+GBoCeZ0O/f3fZ5yxuSvX19VFfX/+VvyYAwObWI38MDQDApiEWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFJiEQCAlFgEACDVZ3NPgJ6vlBIREa2trZt5JgDAhlr7fXvt9/GMWORLa2tri4iIpqamzTwTAGBjtbW1RWNjY7q/pqwvJ2E91qxZE0uWLIn6+vqoqanZ3NPZrFpbW6OpqSneeeedaGho2NzT+Uqz1puGdd40rPOmYZ2rlVKira0tdtxxx+jVK//NRK8s8qX16tUrdt555809jS1KQ0ODf4g2EWu9aVjnTcM6bxrW+X86e0VxLW9wAQAgJRYBAEiJRehCffv2jcmTJ0ffvn0391S+8qz1pmGdNw3rvGlY5y/GG1wAAEh5ZREAgJRYBAAgJRYBAEiJRQAAUmIRNtKKFSti/Pjx0djYGI2NjTF+/Pj4+OOPOz2mlBLXXntt7LjjjrHVVlvFD37wg1iwYEE69thjj42ampr485//3PU30EN0xzp/9NFHcdFFF8WIESOif//+scsuu8TFF18cLS0t3Xw3W47f/e53seuuu0a/fv1i1KhR8de//rXT8XPmzIlRo0ZFv379Yrfddou777673Zjp06fHXnvtFX379o299torZs6c2V3T7zG6ep2nTp0ahx56aGy77bax7bbbxlFHHRUvvfRSd95Cj9AdX89rPfTQQ1FTUxMnn3xyF8+6ByrARhkzZkzZe++9y9y5c8vcuXPL3nvvXU444YROj5kyZUqpr68v06dPL/Pnzy8//vGPy9ChQ0tra2u7sbfeems59thjS0SUmTNndtNdbPm6Y53nz59ffvSjH5XHH3+8vPXWW+WZZ54pe+yxRxk3btymuKXN7qGHHiq1tbVl6tSpZeHCheWSSy4pW2+9dXn77bc7HP+vf/2r9O/fv1xyySVl4cKFZerUqaW2trY89thjlTFz584tvXv3LjfeeGN54403yo033lj69OlTXnjhhU11W1uc7ljn008/vdx5553ltddeK2+88UY5++yzS2NjY3n33Xc31W1tcbpjnddavHhx2Wmnncqhhx5axo4d2813suUTi7ARFi5cWCKi6hthc3NziYjy5ptvdnjMmjVrypAhQ8qUKVMq2/7zn/+UxsbGcvfdd1eNnTdvXtl5553L0qVLv9ax2N3rvK5HHnmk1NXVlVWrVnXdDWyhvve975Xzzz+/atvIkSPLpEmTOhx/xRVXlJEjR1ZtmzhxYjnooIMqz0855ZQyZsyYqjHHHHNMOfXUU7to1j1Pd6zz561evbrU19eXP/7xj19+wj1Ud63z6tWry/e///3yhz/8oUyYMEEsllL8GBo2QnNzczQ2NsaBBx5Y2XbQQQdFY2NjzJ07t8NjFi1aFMuWLYvRo0dXtvXt2zcOP/zwqmNWrlwZp512Wtxxxx0xZMiQ7ruJHqA71/nzWlpaoqGhIfr06dN1N7AF+vTTT+PVV1+tWp+IiNGjR6fr09zc3G78McccE6+88kqsWrWq0zGdrflXWXet8+etXLkyVq1aFdttt13XTLyH6c51vu6662LgwIFxzjnndP3EeyixCBth2bJlMWjQoHbbBw0aFMuWLUuPiYgYPHhw1fbBgwdXHXPppZfGIYccEmPHju3CGfdM3bnO61q+fHlcf/31MXHixC854y3fhx9+GJ999tlGrc+yZcs6HL969er48MMPOx2TnfOrrrvW+fMmTZoUO+20Uxx11FFdM/EeprvW+fnnn4977rknpk6d2j0T76HEIkTEtddeGzU1NZ0+XnnllYiIqKmpaXd8KaXD7ev6/P51j3n88cfj2Wefjdtvv71rbmgLtbnXeV2tra1x/PHHx1577RWTJ0/+EnfVs2zo+nQ2/vPbN/acXwfdsc5r/eY3v4kHH3wwZsyYEf369euC2fZcXbnObW1t8ZOf/CSmTp0aO+ywQ9dPtgf7av/cBTbQhRdeGKeeemqnY4YPHx6vv/56vPfee+32ffDBB+3+i3WttT9SXrZsWQwdOrSy/f33368c8+yzz8Y///nP2GabbaqOHTduXBx66KExe/bsjbibLdfmXue12traYsyYMTFgwICYOXNm1NbWbuyt9Dg77LBD9O7du92rLh2tz1pDhgzpcHyfPn1i++2373RMds6vuu5a57VuueWWuPHGG+Ppp5+Offfdt2sn34N0xzovWLAgFi9eHCeeeGJl/5o1ayIiok+fPvGPf/wjvvGNb3TxnfQMXlmE+O8/PCNHjuz00a9fvzj44IOjpaWl6iMrXnzxxWhpaYlDDjmkw3PvuuuuMWTIkHjqqacq2z799NOYM2dO5ZhJkybF66+/HvPmzas8IiJuu+22uO+++7rvxjexzb3OEf99RXH06NFRV1cXjz/++NfmlZm6uroYNWpU1fpERDz11FPpmh588MHtxj/55JNxwAEHVAI7G5Od86uuu9Y5IuLmm2+O66+/PmbNmhUHHHBA10++B+mOdR45cmTMnz+/6t/hk046KY444oiYN29eNDU1ddv9bPE20xtroMcaM2ZM2XfffUtzc3Npbm4u++yzT7uPdBkxYkSZMWNG5fmUKVNKY2NjmTFjRpk/f3457bTT0o/OWSu+xu+GLqV71rm1tbUceOCBZZ999ilvvfVWWbp0aeWxevXqTXp/m8Pajxq55557ysKFC8svfvGLsvXWW5fFixeXUkqZNGlSGT9+fGX82o8aufTSS8vChQvLPffc0+6jRp5//vnSu3fvMmXKlPLGG2+UKVOm+OicbljnX//616Wurq489thjVV+3bW1tm/z+thTdsc6f593Q/yUWYSMtX768nHHGGaW+vr7U19eXM844o6xYsaJqTESU++67r/J8zZo1ZfLkyWXIkCGlb9++5bDDDivz58/v9Dpf91jsjnV+7rnnSkR0+Fi0aNGmubHN7M477yzDhg0rdXV1Zf/99y9z5syp7JswYUI5/PDDq8bPnj277LfffqWurq4MHz683HXXXe3O+eijj5YRI0aU2traMnLkyDJ9+vTuvo0tXlev87Bhwzr8up08efImuJstV3d8Pa9LLP5XTSn//9udAADwOX5nEQCAlFgEACAlFgEASIlFAABSYhEAgJRYBAAgJRYBAEiJRQAAUmIRAICUWAQAICUWAQBIiUUAAFL/B5G31393IhJ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Model Coeficient Table\n",
    "Model_Coef_Table(model_prediction_revisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e33c90",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Though the exploratory analysis indicated the possibily of finding correlation between transaction patterns and innactivity, the two classifiers and 4 resampling techniques used did not present good performance on this highly imbalanced dataset. \n",
    "\n",
    "The models just didn't perform well! Unfortunatelly. But hey, this is a scientific approach, know that something doesn't work is also a valid result, it just brushes off the false positives from your line of sight.\n",
    "\n",
    "All models had precision scores ranging from 0.08 to 0.09, recall from 0.83 to 0.85 and f1-score at exactlly 0.15. The main difference seeable at the confusion matrix, with slight differences on the true/false positive/negative predictions. The RandomForest with Random Under Sampling had similiar measures: precision at 0.09, recall at 0.77 and f1-score at 0.16.\n",
    "Exemple of Classification Report and Confusion Matrix for the Logistic Regression with Baseline model.\n",
    "\n",
    "The models actually did an interesting job of predicting 325+ cases of the 423 innactivity targets in the test set (you can see that looking at the confusion matrix's top left quadrant, 358 in the example above). That is why the Recall (or sensitivity) is high. \n",
    "\n",
    "This means the model is more confident at trying to predict the minority cases (the Random Forest Baseline practically didn't even try to predict the minority cases, in the report in only classified 15 as negatives, and 14 of them were flase - check the print screen bellow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561716b5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Unfortunately this project doesn't seem to provide strong evidence towards answering either positively or negatively the business question provided.\n",
    "\n",
    "Our exploratory analysis show their is a potential correlation to be explored between innactivaty, depth (specially PIX) and amplitude. But, the use of classifier models, at least with the present configuration, haven't presented promising results.\n",
    "\n",
    "### Recommendations on future studies\n",
    "\n",
    "1. Study the use of time series prediction techniques as a subsititue for Classifiers\n",
    "2. Use the accumlative transactional variation on 5 months prior to the 6th month innactivity prediction may wielf better results than using the absolute number of transations per month as features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
